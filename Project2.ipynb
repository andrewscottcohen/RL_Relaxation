{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "formal-mailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from confutils import get_initial_structure, get_dihedral_info, set_dihedrals_and_relax, relax_structure\n",
    "from tqdm import tqdm\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Activation, Flatten\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from collections import deque\n",
    "from keras_visualizer import visualizer\n",
    "from graphviz import Digraph\n",
    "import pydot_ng as pydot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simplified-bidder",
   "metadata": {},
   "source": [
    "This is my first go at the group project. It currently can one 1 round and actually does minimize energy. That's progress. I'm getting an error with the modified tensor board which I didnt make and I don't know what to do with it. That's my next prject. If you want to have a go at fixing it, be my guest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-knock",
   "metadata": {},
   "source": [
    "# Things you can do:\n",
    "    \n",
    "   1) The convergence criterion doesn't work because it osicillates around a plateau and doesnt ever get to a point where it continually gets worse at the end. Please implement a new finishing criterion that takes the average over the last 100 steps. If the average over 100 steps stops changing significantly, we will define that plateau.\n",
    "   -This requires that you look at the percentage that it changes by at each step and select a percentage that defines a plateau.\n",
    "   \n",
    "   \n",
    "   2) You can pull your own version of this and try to define the intial functions and classes in .py files that can be imported. This got messy with the dependencies so I just shoved them all in here.\n",
    "   3) Find a way to evaluate the accuracy of the fit and prediction of the q values. Add this to the DQNagent. Ask it to plot error as it goes so we can see how it's performing. \n",
    "   \n",
    "   \n",
    "   4) plot all energy values as each game progresses. Do you see any local minima\n",
    "   \n",
    "   \n",
    "   5) the MAIN thing we need is to get it to run for multiple rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "modern-julian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_energy(angles):\n",
    "    \"\"\"Compute the energy of a cysteine molecule given dihedral angles\n",
    "    \n",
    "    Args:\n",
    "        angles: List of dihedral angles\n",
    "    Returns:\n",
    "        energy of the structure\n",
    "    \"\"\"\n",
    "    return set_dihedrals_and_relax(\n",
    "        cysteine,\n",
    "        zip(angles, dihedrals)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "diagnostic-blank",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Atoms(symbols='C2HCO2NSH6', pbc=False, constraint=FixInternals(_copy_init=[FixDihedral(18.902123048141277, [0, 1, 3, 5]), FixDihedral(-62.60246939063225, [3, 1, 0, 7]), FixDihedral(-83.64371381370478, [0, 1, 6, 11]), FixDihedral(-164.48621498151468, [1, 3, 5, 10]), FixDihedral(92.94376035341458, [1, 0, 7, 13])], epsilon=1e-07), calculator=Calculator(...)),\n",
       " [DihedralInfo(chain=[0, 1, 3, 5], group={10, 3, 4, 5}),\n",
       "  DihedralInfo(chain=[3, 1, 0, 7], group={0, 7, 8, 9, 13}),\n",
       "  DihedralInfo(chain=[0, 1, 6, 11], group={11, 12, 6}),\n",
       "  DihedralInfo(chain=[1, 3, 5, 10], group={10, 5}),\n",
       "  DihedralInfo(chain=[1, 0, 7, 13], group={13, 7})],\n",
       " -19641.683481143526,\n",
       " array([  18.90212305,  -62.60246939,  -83.64371381, -164.48621498,\n",
       "          92.94376035]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WIN_REWARD=100\n",
    "MOVE_REWARD=1\n",
    "epsilon=.9\n",
    "eps_decay=.9998\n",
    "start_q_table= None\n",
    "learning=.1\n",
    "discount=.95\n",
    "def get_all(smiles,backbone_atoms,backbone_bonds):\n",
    "    atoms, bonds = get_initial_structure(smiles)\n",
    "   \n",
    "    start_energy = relax_structure(atoms)\n",
    "    diheds=[]\n",
    "    for i in backbone_bonds:\n",
    "        di=get_dihedral_info(bonds,i, backbone_atoms=backbone_atoms)\n",
    "        diheds.append(di)\n",
    "        \n",
    "    init_state=np.random.uniform(-180,180,len(diheds))\n",
    "    \n",
    "    energy=set_dihedrals_and_relax(\n",
    "        atoms,\n",
    "        zip(init_state, diheds)\n",
    "    )\n",
    "    \n",
    "    return atoms, diheds,energy,init_state\n",
    "\n",
    "      \n",
    "    \n",
    "get_all('C([C@@H](C(=O)O)N)S',[0, 1, 3, 5, 6, 7],[[1,3],[1, 0],[1, 6],[3, 5],[0, 7]])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "right-southwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Molecule:\n",
    "    def __init__(self,smiles,backbone_atoms,backbone_bonds):\n",
    "        self.bbonds=backbone_bonds\n",
    "        self.n_choices=len(self.bbonds)\n",
    "        self.atoms, self.dihedrals, self.energy, self.angles=get_all(smiles,backbone_atoms,backbone_bonds)\n",
    "    def get_energy(self):\n",
    "        self.energy=set_dihedrals_and_relax(self.atoms,zip(self.angles, self.dihedrals))\n",
    "        return self.energy\n",
    "    choices=[]\n",
    "    #def action(self,choice):\n",
    "        #if choice %2 ==0:\n",
    "            #self.angles[int(choice/2)]+=1.0\n",
    "            #if abs(self.angles[int(choice/2)])>180:\n",
    "                #self.angles[int(choice/2)]=self.angles[int(choice/2)]%180\n",
    "            \n",
    "        #else:\n",
    "            #self.angles[int(np.round(choice/2))]-=1.0\n",
    "            #if abs(self.angles[int(choice/2)])>180:\n",
    "                #self.angles[int(choice/2)]=self.angles[int(choice/2)]%180\n",
    "                \n",
    "\n",
    "    def action(self,choice):\n",
    "        if choice==0:\n",
    "            self.angles[0]+=1.0\n",
    "            if abs(self.angles[0])>180:\n",
    "                self.angles[0]=self.angles[0]%180\n",
    "        if choice==1:\n",
    "            self.angles[0]-=1.0\n",
    "            if abs(self.angles[0])>180:\n",
    "                self.angles[0]=self.angles[0]%180\n",
    "        if choice==2:\n",
    "            self.angles[1]+=1.0\n",
    "            if abs(self.angles[1])>180:\n",
    "                self.angles[1]=self.angles[1]%180\n",
    "        if choice==3:\n",
    "            self.angles[1]-=1.0\n",
    "            if abs(self.angles[1])>180:\n",
    "                self.angles[1]=self.angles[1]%180\n",
    "        if choice==4:\n",
    "            self.angles[1]+=1.0\n",
    "            if abs(self.angles[1])>180:\n",
    "                self.angles[1]=self.angles[1]%180\n",
    "        if choice==5:\n",
    "            self.angles[1]-=1.0\n",
    "            if abs(self.angles[1])>180:\n",
    "                self.angles[1]=self.angles[1]%180\n",
    "        if choice==6:\n",
    "            self.angles[1]+=1.0\n",
    "            if abs(self.angles[1])>180:\n",
    "                self.angles[1]=self.angles[1]%180\n",
    "        if choice==7:\n",
    "            self.angles[1]+=1.0\n",
    "            if abs(self.angles[1])>180:\n",
    "                self.angles[1]=self.angles[1]%180\n",
    "        if choice==8:\n",
    "            self.angles[1]+=1.0\n",
    "            if abs(self.angles[1])>180:\n",
    "                self.angles[1]=self.angles[1]%180\n",
    "        if choice==9:\n",
    "            self.angles[1]-=1.0\n",
    "            if abs(self.angles[1])>180:\n",
    "                self.angles[1]=self.angles[1]%180\n",
    "           \n",
    "\n",
    "\n",
    "            \n",
    "class MolEnv:\n",
    "    mol = Molecule('C([C@@H](C(=O)O)N)S',[0, 1, 3, 5, 6, 7],[[1,3],[1, 0],[1, 6],[3, 5],[0, 7]])\n",
    "    SIZE = 360 #We dont have a finite size in this way\n",
    "    RETURN_IMAGES = False\n",
    "    ENERGY_REWARD=1\n",
    "    MIN_REWARD = 25\n",
    "    OBSERVATION_SPACE_VALUES = [360 for i in range(mol.n_choices)]\n",
    "    OBSERVATION_SPACE_VALUES.append(mol.n_choices)\n",
    "    ACTION_SPACE_SIZE = mol.n_choices*2\n",
    "    OBSERVATION_SPACE_VALUES=tuple(OBSERVATION_SPACE_VALUES)\n",
    "    reward=0\n",
    "    MAX_STEPS=200000\n",
    "    EXIT=False\n",
    "    min_energy=mol.get_energy()+.05\n",
    "    def __init__(self):\n",
    "        self.energy_list=[]\n",
    "        self.ener=self.mol.get_energy()\n",
    "        self.min_energy=self.ener+.05\n",
    "        self.reward=0\n",
    "        self.EXIT==False\n",
    "    def reset(self):\n",
    "        self.mol = Molecule('C([C@@H](C(=O)O)N)S',[0, 1, 3, 5, 6, 7],[[1,3],[1, 0],[1, 6],[3, 5],[0, 7]])\n",
    "        self.ener=self.mol.get_energy()\n",
    "        \n",
    "        self.strikes=0\n",
    "        self.energy_list=[]\n",
    "        self.energy_list.append(self.ener)\n",
    "        OBSERVATION_SPACE_VALUES = [360 for i in range(self.mol.n_choices)]\n",
    "        OBSERVATION_SPACE_VALUES.append(self.mol.n_choices)# 4 #WHAT IS GOING ON HERE\n",
    "        \n",
    "        OBSERVATION_SPACE_VALUES=tuple(OBSERVATION_SPACE_VALUES)\n",
    "        self.episode_step = 0\n",
    "\n",
    "        if self.RETURN_IMAGES:\n",
    "            observation = np.array(self.get_image())\n",
    "        else:\n",
    "            observation = self.mol.angles\n",
    "        return observation\n",
    "\n",
    "    def step(self, action):\n",
    "        self.reward=0\n",
    "        self.episode_step += 1\n",
    "        \n",
    "        self.mol.action(action)\n",
    "        new_ener=self.mol.get_energy()\n",
    "        print(new_ener,\"NEW EN\")\n",
    "        self.energy_list.append(new_ener)\n",
    "    \n",
    "        \n",
    "        \n",
    "        new_observation = self.mol.angles\n",
    "        \n",
    "        done = False\n",
    "        \n",
    "        if abs(new_ener)<=abs(self.min_energy):\n",
    "            self.min_energy=new_ener\n",
    "            self.reward=10000\n",
    "            plt.plot(np.arange(0,len(self.energy_list)),self.energy_list)\n",
    "            done = True\n",
    "\n",
    "        if self.episode_step>MAX_STEPS and new_ener==self.min_energy:\n",
    "            done=True\n",
    "        \n",
    "\n",
    "        \n",
    "        return new_observation, self.reward, done, self.mol.angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "intended-accommodation",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLAY_MEMORY_SIZE = 4000\n",
    "MIN_REPLAY_MEMORY_SIZE = 1000\n",
    "MODEL_NAME = \"256x2\"\n",
    "DISCOUNT=0.99\n",
    "MINIBATCH_SIZE = 64  # How many steps (samples) to use for training\n",
    "UPDATE_TARGET_EVERY = 5  # Terminal states (end of episodes)\n",
    "MIN_EPSILON=.5\n",
    "class DQNAgent:\n",
    "    \n",
    "    def __init__(self,env):\n",
    "\n",
    "        # main model  # gets trained every step\n",
    "        self.model = self.create_model()\n",
    "\n",
    "        # Target model this is what we .predict against every step\n",
    "        self.target_model = self.create_model()\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "        self.replay_memory = deque(maxlen=REPLAY_MEMORY_SIZE)\n",
    "        self.target_update_counter = 0\n",
    "\n",
    "    def create_model(self):\n",
    "        \n",
    "        model = Sequential()\n",
    "        #model.add(Conv2D(256, (3, 3), input_shape=env.OBSERVATION_SPACE_VALUES))\n",
    "        #model.add(keras.Input(shape=(REPLAY_MEMORY_SIZE,a1.n_choices)))\n",
    "        model.add(keras.Input(shape=(a1.n_choices)))\n",
    "        model.add(Dense(a1.n_choices))\n",
    "\n",
    "        #model.add(Flatten())\n",
    "        \n",
    "        model.add(Dense(a1.n_choices,activation='linear'))\n",
    "\n",
    "        model.add(Dense(env.ACTION_SPACE_SIZE, activation='linear'))\n",
    "        model.compile(loss=\"mse\", optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def update_replay_memory(self, transition):\n",
    "        self.replay_memory.append(transition)\n",
    "\n",
    "    def get_qs(self, state, step):\n",
    "        #print(*state.shape)\n",
    "        return self.model.predict(np.array(state).reshape(-1, *state.shape)/180)[0]\n",
    "    def train(self, terminal_state,step):\n",
    "        if len(self.replay_memory)<MIN_REPLAY_MEMORY_SIZE:\n",
    "            return\n",
    "    # Get a minibatch of random samples from memory replay table\n",
    "        minibatch = random.sample(self.replay_memory, MINIBATCH_SIZE)\n",
    "\n",
    "        # Get current states from minibatch, then query NN model for Q values\n",
    "        current_states = np.array([transition[0] for transition in minibatch])/180\n",
    "        current_qs_list = self.model.predict(current_states)\n",
    "\n",
    "        # Get future states from minibatch, then query NN model for Q values\n",
    "        # When using target network, query it, otherwise main network should be queried\n",
    "        new_current_states = np.array([transition[3] for transition in minibatch])/180\n",
    "        future_qs_list = self.target_model.predict(new_current_states)\n",
    "        \n",
    "        X = []\n",
    "        y = []\n",
    "\n",
    "        # Now we need to enumerate our batches\n",
    "        for index, (current_state, action, reward, new_current_state, done) in enumerate(minibatch):\n",
    "\n",
    "            # If not a terminal state, get new q from future states, otherwise set it to 0\n",
    "            # almost like with Q Tabel Learning, but we use just part of equation here\n",
    "            if not done:\n",
    "                max_future_q = np.max(future_qs_list[index])\n",
    "                new_q = reward + DISCOUNT * max_future_q\n",
    "            else:\n",
    "                new_q = reward\n",
    "\n",
    "            # Update Q value for given state\n",
    "            current_qs = current_qs_list[index]\n",
    "            current_qs[action] = new_q\n",
    "\n",
    "            # And append to our training data\n",
    "            X.append(current_state)\n",
    "            y.append(current_qs)\n",
    "\n",
    "        # Fit on all samples as one batch, log only on terminal state\n",
    "        self.model.fit(np.array(X)/180, np.array(y), batch_size=MINIBATCH_SIZE, verbose=0, shuffle=False)\n",
    "\n",
    "        # Update target network counter every episode\n",
    "                # Update target network counter every episode\n",
    "        if terminal_state:\n",
    "            self.target_update_counter += 1\n",
    "\n",
    "        # If counter reaches set value, update target network with weights of main network\n",
    "        if self.target_update_counter > UPDATE_TARGET_EVERY:\n",
    "            self.target_model.set_weights(self.model.get_weights())\n",
    "            self.target_update_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "everyday-contrary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 102.10712711   38.55490844  162.19888513  -91.48728529 -161.84671205]\n",
      "[ 102.10712711   39.55490844  162.19888513  -91.48728529 -161.84671205]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a1=Molecule('C([C@@H](C(=O)O)N)S',[0, 1, 3, 5, 6, 7],[[1,3],[1, 0],[1, 6],[3, 5],[0, 7]])\n",
    "print(a1.angles)\n",
    "a1.action(2)\n",
    "print(a1.angles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-general",
   "metadata": {},
   "source": [
    "# This is the part that actually runs the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "moving-lightning",
   "metadata": {},
   "outputs": [],
   "source": [
    "env=MolEnv()\n",
    "EPISODES = 5\n",
    "agent = DQNAgent(env)\n",
    "epsilon=.9\n",
    "EPSILON_DECAY=.98\n",
    "AGGREGATE_STATS_EVERY=10\n",
    "MAX_STEPS=200#000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "encouraging-venezuela",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|###############6                                                              | 1/5 [00:32<02:08, 32.07s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-19641.045079097203 NEW EN\n",
      "-19641.391229316538 NEW EN\n",
      "-19641.388440011022 NEW EN\n",
      "-19641.39122951928 NEW EN\n",
      "-19641.392889762254 NEW EN\n",
      "-19641.39554079866 NEW EN\n",
      "-19641.393932051804 NEW EN\n",
      "-19641.39654943327 NEW EN\n",
      "-19641.3990832856 NEW EN\n",
      "-19641.401557532183 NEW EN\n",
      "-19641.400236879752 NEW EN\n",
      "-19641.397700594538 NEW EN\n",
      "-19641.395106933727 NEW EN\n",
      "-19641.397700391797 NEW EN\n",
      "-19641.400236068792 NEW EN\n",
      "-19641.397699986315 NEW EN\n",
      "-19641.400236879752 NEW EN\n",
      "-19641.399043953916 NEW EN\n",
      "-19641.396439142372 NEW EN\n",
      "-19641.399043548437 NEW EN\n",
      "-19641.39798017386 NEW EN\n",
      "-19641.400629993823 NEW EN\n",
      "-19641.40326683839 NEW EN\n",
      "-19641.402513454228 NEW EN\n",
      "-19641.40326764935 NEW EN\n",
      "-19641.405897803477 NEW EN\n",
      "-19641.403268460315 NEW EN\n",
      "-19641.402512035045 NEW EN\n",
      "-19641.405235652597 NEW EN\n",
      "-19641.407954404374 NEW EN\n",
      "-19641.405235247115 NEW EN\n",
      "-19641.402514467933 NEW EN\n",
      "-19641.401902191246 NEW EN\n",
      "-19641.401431022034 NEW EN\n",
      "-19641.401104204146 NEW EN\n",
      "-19641.404105981837 NEW EN\n",
      "-19641.404339741777 NEW EN\n",
      "-19641.404104968133 NEW EN\n",
      "-19641.401104609628 NEW EN\n",
      "-19641.404103143468 NEW EN\n",
      "-19641.40401272115 NEW EN\n",
      "-19641.40091727729 NEW EN\n",
      "-19641.404013532112 NEW EN\n",
      "-19641.40406198712 NEW EN\n",
      "-19641.407261031436 NEW EN\n",
      "-19641.40711566641 NEW EN\n",
      "-19641.407260220476 NEW EN\n",
      "-19641.410465144272 NEW EN\n",
      "-19641.413670473547 NEW EN\n",
      "-19641.41332459804 NEW EN\n",
      "-19641.41312206016 NEW EN\n",
      "-19641.416113498075 NEW EN\n",
      "-19641.419083040008 NEW EN\n",
      "-19641.42202500921 NEW EN\n",
      "-19641.424927849475 NEW EN\n",
      "-19641.427789736135 NEW EN\n",
      "-19641.42852730653 NEW EN\n",
      "-19641.425554318008 NEW EN\n",
      "-19641.4263308146 NEW EN\n",
      "-19641.427251257035 NEW EN\n",
      "-19641.42401389474 NEW EN\n",
      "-19641.420746121352 NEW EN\n",
      "-19641.4215862785 NEW EN\n",
      "-19641.422570786974 NEW EN\n",
      "-19641.41905871113 NEW EN\n",
      "-19641.420065521073 NEW EN\n",
      "-19641.42368646863 NEW EN\n",
      "-19641.427296468195 NEW EN\n",
      "-19641.43088132792 NEW EN\n",
      "-19641.434435979296 NEW EN\n",
      "-19641.43296408236 NEW EN\n",
      "-19641.434436790256 NEW EN\n",
      "-19641.43794906884 NEW EN\n",
      "-19641.44140904034 NEW EN\n",
      "-19641.44480616225 NEW EN\n",
      "-19641.446773557273 NEW EN\n",
      "-19641.44325904854 NEW EN\n",
      "-19641.446773962754 NEW EN\n",
      "-19641.443259656764 NEW EN\n",
      "-19641.446774976455 NEW EN\n",
      "-19641.450211632786 NEW EN\n",
      "-19641.44677599016 NEW EN\n",
      "-19641.4432588458 NEW EN\n",
      "-19641.44140904034 NEW EN\n",
      "-19641.43794927158 NEW EN\n",
      "-19641.43443374915 NEW EN\n",
      "-19641.430881936143 NEW EN\n",
      "-19641.42729545449 NEW EN\n",
      "-19641.430882747107 NEW EN\n",
      "-19641.43443395189 NEW EN\n",
      "-19641.437949879804 NEW EN\n",
      "-19641.439679662813 NEW EN\n",
      "-19641.43794927158 NEW EN\n",
      "-19641.43443456011 NEW EN\n",
      "-19641.4329652988 NEW EN\n",
      "-19641.43443476285 NEW EN\n",
      "-19641.436046145336 NEW EN\n",
      "-19641.432371674255 NEW EN\n",
      "-19641.43399927599 NEW EN\n",
      "-19641.437795188707 NEW EN\n",
      "-19641.441548931372 NEW EN\n",
      "-19641.439679460073 NEW EN\n",
      "-19641.443259656764 NEW EN\n",
      "-19641.439681487478 NEW EN\n",
      "-19641.436047564523 NEW EN\n",
      "-19641.43779559419 NEW EN\n",
      "-19641.441549336854 NEW EN\n",
      "-19641.44524773133 NEW EN\n",
      "-19641.44154812041 NEW EN\n",
      "-19641.44524732585 NEW EN\n",
      "-19641.448880032363 NEW EN\n",
      "-19641.452430426183 NEW EN\n",
      "-19641.45588593739 NEW EN\n",
      "-19641.459235415252 NEW EN\n",
      "-19641.462462437776 NEW EN\n",
      "-19641.465559300817 NEW EN\n",
      "-19641.468512623498 NEW EN\n",
      "-19641.465558084376 NEW EN\n",
      "-19641.468514650907 NEW EN\n",
      "-19641.471314498933 NEW EN\n",
      "-19641.46851282624 NEW EN\n",
      "-19641.47131368797 NEW EN\n",
      "-19641.473950938016 NEW EN\n",
      "-19641.47694724171 NEW EN\n",
      "-19641.474238424224 NEW EN\n",
      "-19641.47694724171 NEW EN\n",
      "-19641.47423761326 NEW EN\n",
      "-19641.476949066375 NEW EN\n",
      "-19641.479470957005 NEW EN\n",
      "-19641.48263634638 NEW EN\n",
      "-19641.48589763207 NEW EN\n",
      "-19641.488316530464 NEW EN\n",
      "-19641.490503088102 NEW EN\n",
      "-19641.49391926763 NEW EN\n",
      "-19641.491705137265 NEW EN\n",
      "-19641.488316733205 NEW EN\n",
      "-19641.491704731783 NEW EN\n",
      "-19641.495167947134 NEW EN\n",
      "-19641.492670385378 NEW EN\n",
      "-19641.48993460339 NEW EN\n",
      "-19641.48697560397 NEW EN\n",
      "-19641.489933792425 NEW EN\n",
      "-19641.493395588594 NEW EN\n",
      "-19641.496926924796 NEW EN\n",
      "-19641.493873448246 NEW EN\n",
      "-19641.490599187156 NEW EN\n",
      "-19641.48711427856 NEW EN\n",
      "-19641.483441429402 NEW EN\n",
      "-19641.486824562206 NEW EN\n",
      "-19641.482900517414 NEW EN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|###############4                                                             | 1/5 [10:44<42:58, 644.60s/episodes]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-a6d2c06b37a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACTION_SPACE_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mnew_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mANGLES\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0mangles_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mANGLES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-aad9b729c143>\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mnew_ener\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_energy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_ener\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"NEW EN\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menergy_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_ener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-f46109f74089>\u001b[0m in \u001b[0;36mget_energy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matoms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdihedrals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menergy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mangles\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msmiles\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbackbone_atoms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbackbone_bonds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_energy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menergy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mset_dihedrals_and_relax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matoms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mangles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdihedrals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menergy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mchoices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\UChicago\\Academics\\2020-21\\Q2 2021\\AI for MatSci\\RLRelaxation--main\\confutils.py\u001b[0m in \u001b[0;36mset_dihedrals_and_relax\u001b[1;34m(atoms, dihedrals)\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[0matoms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_constraint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFixInternals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdihedrals_deg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdih_cnsts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrelax_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0matoms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\UChicago\\Academics\\2020-21\\Q2 2021\\AI for MatSci\\RLRelaxation--main\\confutils.py\u001b[0m in \u001b[0;36mrelax_structure\u001b[1;34m(atoms)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mdyn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBFGS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0matoms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevnull\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[0mdyn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0matoms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_potential_energy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\oed_3\\lib\\site-packages\\ase\\optimize\\optimize.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fmax, steps)\u001b[0m\n\u001b[0;32m    292\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mDynamics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconverged\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforces\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\oed_3\\lib\\site-packages\\ase\\optimize\\optimize.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    179\u001b[0m         *steps*.\"\"\"\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mconverged\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mDynamics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mirun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mconverged\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\oed_3\\lib\\site-packages\\ase\\optimize\\optimize.py\u001b[0m in \u001b[0;36mirun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m             \u001b[1;31m# log the step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_observers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\oed_3\\lib\\site-packages\\ase\\optimize\\optimize.py\u001b[0m in \u001b[0;36mlog\u001b[1;34m(self, forces)\u001b[0m\n\u001b[0;32m    306\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforces\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforces\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m             \u001b[0mforces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matoms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_forces\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m         \u001b[0mfmax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforces\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m         e = self.atoms.get_potential_energy(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\oed_3\\lib\\site-packages\\ase\\atoms.py\u001b[0m in \u001b[0;36mget_forces\u001b[1;34m(self, apply_constraint, md)\u001b[0m\n\u001b[0;32m    788\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_calc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Atoms object has no calculator.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 790\u001b[1;33m         \u001b[0mforces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_calc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_forces\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    791\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mapply_constraint\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\oed_3\\lib\\site-packages\\ase\\calculators\\abc.py\u001b[0m in \u001b[0;36mget_forces\u001b[1;34m(self, atoms)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_forces\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0matoms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_property\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'forces'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0matoms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_stress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0matoms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\oed_3\\lib\\site-packages\\ase\\calculators\\calculator.py\u001b[0m in \u001b[0;36mget_property\u001b[1;34m(self, name, atoms, allow_calculation)\u001b[0m\n\u001b[0;32m    734\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_calculation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalculate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0matoms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msystem_changes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\oed_3\\lib\\site-packages\\torchani\\ase.py\u001b[0m in \u001b[0;36mcalculate\u001b[1;34m(self, atoms, properties, system_changes)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'forces'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mproperties\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[0mforces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menergy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoordinates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'stress'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mproperties\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'forces'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\oed_3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[0;32m    155\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[0;32m    156\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m         inputs, allow_unused)\n\u001b[0m\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "SHOW_PREVIEW=False\n",
    "ep_rewards=[]\n",
    "angles_list=[]\n",
    "#energy_min=-1941.0 #This needs to be defined for each structure. This should be the open babel gradient descent min. \n",
    "for episode in tqdm(range(1, EPISODES + 1), ascii=True, unit='episodes'):\n",
    "\n",
    "    #while env.EXIT==False:\n",
    "\n",
    "    # Restarting episode - reset episode reward and step number\n",
    "    episode_reward = 0\n",
    "    step = 1\n",
    "\n",
    "    # Reset environment and get initial state\n",
    "    current_state = env.reset()\n",
    "\n",
    "    # Reset flag and start iterating until episode ends\n",
    "    done = False\n",
    "    while not done:\n",
    "\n",
    "        # This part stays mostly the same, the change is to query a model for Q values\n",
    "        if np.random.random() > epsilon:\n",
    "            # Get action from Q table\n",
    "            action = np.argmax(agent.get_qs(current_state,step))\n",
    "        else:\n",
    "            # Get random action\n",
    "            action = np.random.randint(0, env.ACTION_SPACE_SIZE)\n",
    "\n",
    "        new_state, reward, done, ANGLES = env.step(action)\n",
    "        angles_list.append(ANGLES)\n",
    "        \n",
    "\n",
    "        # Transform new continous state to new discrete state and count reward\n",
    "        episode_reward += reward\n",
    "\n",
    "        # Every step we update replay memory and train main network\n",
    "        agent.update_replay_memory((current_state, action, reward, new_state, done))\n",
    "        agent.train(done, step)\n",
    "\n",
    "        current_state = new_state\n",
    "        step += 1\n",
    "    #episode+=1\n",
    "    #print(\"DONE\")\n",
    "    # Append episode reward to a list and log stats (every given number of episodes)\n",
    "    ep_rewards.append(episode_reward)\n",
    "    if not episode % AGGREGATE_STATS_EVERY or episode == 1:\n",
    "        average_reward = sum(ep_rewards[-AGGREGATE_STATS_EVERY:])/len(ep_rewards[-AGGREGATE_STATS_EVERY:])\n",
    "        min_reward = min(ep_rewards[-AGGREGATE_STATS_EVERY:])\n",
    "        max_reward = max(ep_rewards[-AGGREGATE_STATS_EVERY:])\n",
    "        #agent.tensorboard.update_stats(reward_avg=average_reward, reward_min=min_reward, reward_max=max_reward, epsilon=epsilon)\n",
    "\n",
    "        # Save model, but only when min reward is greater or equal a set value\n",
    "        #if min_reward >= MIN_REWARD:\n",
    "            #agent.model.save(f'models/{MODEL_NAME}__{max_reward:_>7.2f}max_{average_reward:_>7.2f}avg_{min_reward:_>7.2f}min__{int(time.time())}.model')\n",
    "\n",
    "    # Decay epsilon\n",
    "    if epsilon > MIN_EPSILON:\n",
    "        epsilon *= EPSILON_DECAY\n",
    "        epsilon = max(MIN_EPSILON, epsilon)\n",
    "plt.legend([str(i) for i in range(EPISODES)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-interpretation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "starting-flight",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(self):\n",
    "        \n",
    "        model = Sequential(name = 'DQN: Cysteine')\n",
    "        #model.add(Conv2D(256, (3, 3), input_shape=env.OBSERVATION_SPACE_VALUES))\n",
    "        #model.add(keras.Input(shape=(REPLAY_MEMORY_SIZE,a1.n_choices)))\n",
    "        model.add(keras.Input(shape=(a1.n_choices)))\n",
    "        model.add(Dense(a1.n_choices))\n",
    "\n",
    "        #model.add(Flatten())\n",
    "        \n",
    "        model.add(Dense(a1.n_choices,activation='linear'))\n",
    "\n",
    "        model.add(Dense(env.ACTION_SPACE_SIZE, activation='linear'))\n",
    "        model.compile(loss=\"mse\", optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "touched-conviction",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "virgin-think",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"DQN: Cysteine\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                60        \n",
      "=================================================================\n",
      "Total params: 120\n",
      "Trainable params: 120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "behind-cornell",
   "metadata": {},
   "outputs": [],
   "source": [
    "pydot.find_graphviz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "favorite-madonna",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer(model, filename = r\"C:\\Users\\ascoh\\graph\", format = 'png', view = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-corpus",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
